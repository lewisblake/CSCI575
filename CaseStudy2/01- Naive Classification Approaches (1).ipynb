{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "37f776e4e1c8c3965f5bc354f8a83aef",
     "grade": false,
     "grade_id": "cell-c3b11c5d81596cb7",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    " As this is a case study individual assignment, I agree and acknowledge that all code modified in this notebook is my own. I have not and will not collaborate with anyone on this assignment. If I have questions, I will ask the instructor or TAs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "029dbc0bc45912b6ed8a9d4e68876a98",
     "grade": false,
     "grade_id": "cell-7a410150ea339a11",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Please provide your name and agreement to the above statement as variables `name` (string) and `agree` (boolean)\n",
    "# YOUR CODE HERE\n",
    "name = \"Lewis Blake\"\n",
    "agree = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "af5055b179decaf7c280171f297f036c",
     "grade": true,
     "grade_id": "cell-be8f2fd5450b57d8",
     "locked": true,
     "points": 0,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "conditions = [isinstance(name, str), isinstance(agree, bool), agree]\n",
    "for condition in conditions:\n",
    "    if not condition:\n",
    "        raise ValueError(\"Student has not agreed to work on this assignment alone and without collaboration or has not provided their name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4d0698f98a2a7060ac16b6b48aeff7fd",
     "grade": false,
     "grade_id": "cell-331eb85546d2d12e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Naive Classification Approaches\n",
    "\n",
    "\n",
    "In this case study, we will build a custom classifier that takes some naive classification approaches. The approaches we'll take are:\n",
    "\n",
    "- Guessing one class at all times\n",
    "- Guessing the most common class at all times\n",
    "- Guessing randomly based on the distribution of the classes\n",
    "- Guessing randomly based on an equal chance of the classes\n",
    "\n",
    "\n",
    "We're going to build a class, `NaiveClassifier`, that can fit and predict based on the above approaches. We will then try it out on a few datasets and see what results we get. This should help you understand the minimal performance you should expect out of your machine learning models.\n",
    "\n",
    "The way `NaiveClassifier` should work is that we instantiate it with an `approach` and an optional `value` depending on the method.\n",
    "\n",
    "Examples:\n",
    "\n",
    "- always predict class 1 would be: `clf = NaiveClassifier(approach=\"always\", value=1)`\n",
    "- always predict most common class would be: `clf = NaiveClassifier(approach=\"most\")`\n",
    "- predict based on class distribution: `clf = NaiveClassifier(approach=\"distribution\")`\n",
    "- predict based on equal class distribution: `clf = NaiveClassifier(approach=\"equal\")`\n",
    "\n",
    "Note that as a naive classifier, this classifier is not using any of the features about the data. It is only using the patterns that it detects in the labels.\n",
    "\n",
    "In addition, recall that the way a supervised learning classifier works is that it is:\n",
    "\n",
    "- Initialized with its hyperparameters\n",
    "- When running `.fit()`, it learns its model parameters such as the weight coefficients in linear regression.\n",
    "- When running `.predict`, it applies the model parameters that it learned to the new data such as plugging in values of $x$ into the equation $y=mx+b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7150a9a2cf9e261ee812b05e651f385f",
     "grade": false,
     "grade_id": "cell-9213e34f09e91de2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import stats\n",
    "import sklearn\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "612b4a613bb8950aaa69fc8bdd1a9974",
     "grade": false,
     "grade_id": "cell-2072e6f2de42e5af",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def select_most_common(labels):\n",
    "    \"\"\"Select the most common value in an iterable of labels\n",
    "    \n",
    "    Args:\n",
    "        labels (iterable): An iterable of integers representing the labels of a dataset\n",
    "    \n",
    "    Returns:\n",
    "        int: The most common element in the iterable\n",
    "    \"\"\"\n",
    "    return max(set(labels), key = labels.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7f10cadf9d39cca14641dae7f0c71454",
     "grade": true,
     "grade_id": "cell-8e5505cea4302a14",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert select_most_common([1,2,2,3,4,5]) == 2\n",
    "assert select_most_common([1,1,1,1,1,1,2,2,2]) == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ff9f379b5c97f08e2e1294c6fc237c83",
     "grade": false,
     "grade_id": "cell-325a895cdb54e984",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "In this next portion, we will generate data following a distribution. Let's go over a simple example of how to do that. If we want to simulate a fair coin flip, we know that 50% of the time we should get heads, and 50% of the time we should get tails. We can create a simulated fair coin programmatically by generating a *uniform* random number between 0 and 1, and deciding that if it is less than 0.5, we get heads, and if it is greater than or equal to 0.5 we get tails. We can programatically represent the distribution of heads and tails as `[0.5, 0.5]` where heads is class 0 and tails is class 1. In the next function, you will write a function to generate data / predict from a distribution where the distribution is represented that way and can be of any length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "62dd94396852ddf43fe6481a9bcc2448",
     "grade": true,
     "grade_id": "cell-4547cb50665c9747",
     "locked": false,
     "points": 20,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def predict_from_distribution(distribution):\n",
    "    \"\"\"Return one possible value given a distribution\n",
    "    \n",
    "    Args:\n",
    "        distribution (list): A list of probabilities of each class index\n",
    "        \n",
    "    Returns:\n",
    "        int: The index of the predicted class.\n",
    "    \"\"\"\n",
    "    assert sum(distribution) == 1\n",
    "    class_labels = list(range(len(distribution)))\n",
    "    return np.random.choice(class_labels, p=distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8ebc09ff2b2ab3f7a2f880ec0ceebcf1",
     "grade": false,
     "grade_id": "cell-bcf996323af296d9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 0, 2, 1, 2, 0, 0, 2, 0]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example predictions\n",
    "# You should see 10 results with about 5 0s, 1 1, and 4 2's.\n",
    "# You can print val in order to see if it's being calculated correctly\n",
    "[predict_from_distribution([0.5, 0.1, 0.4]) for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d98b468ae54931df1cb7161cde8f1e4a",
     "grade": false,
     "grade_id": "cell-317516af1385c134",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "class NaiveClassifier:\n",
    "    \"\"\"A Naive Classifier that predicts classes using simple approaches.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, approach, value=None):\n",
    "        \"\"\"Initialize the NaiveClassifier\n",
    "        \n",
    "        Args:\n",
    "            approach (str): One of \"always\", \"most\", \"distribution\", \"equal\"\n",
    "            value (int, optional): Defaults to None. The value of the class to select if approach is \"always\"\n",
    "        \"\"\"\n",
    "        assert approach in [\"always\", \"most\", \"distribution\", \"equal\"]\n",
    "        self.approach = approach\n",
    "        self.value = value\n",
    "\n",
    "    def fit(self,X,y):\n",
    "        \"\"\"Fit to data and labels\n",
    "        \n",
    "        Args:\n",
    "            X (iterable): The features of the data\n",
    "            y (iterable): The labels of the data\n",
    "        \"\"\"\n",
    "        if self.approach == \"always\":\n",
    "            # YOUR CODE HERE\n",
    "            raise NotImplementedError()\n",
    "        elif self.approach == \"most\":\n",
    "            # YOUR CODE HERE\n",
    "            raise NotImplementedError()\n",
    "        elif self.approach == \"distribution\":\n",
    "            # YOUR CODE HERE\n",
    "            raise NotImplementedError()\n",
    "        elif self.approach == \"equal\":\n",
    "            # YOUR CODE HERE\n",
    "            raise NotImplementedError()\n",
    "\n",
    "    def predict(self,X):\n",
    "        \"\"\"Predict the labels of a new set of datapoints\n",
    "        \n",
    "        Args:\n",
    "            X (iterable): The data to predict\n",
    "        \"\"\"\n",
    "        if self.approach == \"always\":\n",
    "            # YOUR CODE HERE\n",
    "            raise NotImplementedError()\n",
    "        elif self.approach == \"most\":\n",
    "            # YOUR CODE HERE\n",
    "            raise NotImplementedError()\n",
    "        elif self.approach == \"distribution\":\n",
    "            # YOUR CODE HERE\n",
    "            raise NotImplementedError()\n",
    "        elif self.approach == \"equal\":\n",
    "            # YOUR CODE HERE\n",
    "            raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8c4619d46be0064b24af31c290541474",
     "grade": false,
     "grade_id": "cell-a22c0b698e77fade",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Let's create a few datasets that we'll use to analyze how a predictor would work with each of those approaches. Here are all the datasets we'll create:\n",
    "\n",
    "- 2 classes equally distributed\n",
    "- 2 classes with 0 at 90% and 1 at 10%\n",
    "- 3 classes equally distributed\n",
    "- 3 classes with 0 at 90%, 1 at 9% and 2 at 1%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "815c4a748b18da09e242491d772a3f70",
     "grade": false,
     "grade_id": "cell-41dd1414621c39ae",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# We will create the labels for each of the listed datasets with length n\n",
    "# Create the listed datasets as binary_equal, binary_unequal, trinary_equal and trinary_unequal\n",
    "n = 15000\n",
    "features = np.zeros((n,3))\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "95b318c451acafebc1ef5cf792408b8b",
     "grade": true,
     "grade_id": "cell-7458977b6dde20e7",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.all(np.bincount(binary_equal) == np.array([7500,7500]))\n",
    "assert np.all(np.bincount(binary_unequal) == np.array([13500,1500]))\n",
    "assert np.all(np.bincount(trinary_equal) == np.array([5000,5000,5000]))\n",
    "assert np.all(np.bincount(trinary_unequal) == np.array([13500,1350,150]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1695b48d77fcea33800cc7d8d2fe39f0",
     "grade": false,
     "grade_id": "cell-900b0957df9f3734",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "datasets = [{\n",
    "    \"name\": \"Binary Classification Equally Distributed\",\n",
    "    \"labels\": binary_equal\n",
    "},{\n",
    "    \"name\": \"Binary Classification 90:10\",\n",
    "    \"labels\": binary_unequal\n",
    "},{\n",
    "    \"name\": \"3-Class Classification Equally Distributed\",\n",
    "    \"labels\": trinary_equal\n",
    "},{\n",
    "    \"name\": \"3-Class Classification 90:9:1\",\n",
    "    \"labels\": trinary_unequal\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0ae7ec3f0991ed547340d10b66be6e30",
     "grade": false,
     "grade_id": "cell-c91e34d42c72031a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Testing\n",
    "\n",
    "Let's now test out our Naive Classifiers on the above datasets. We will be training and testing on the full dataset. Since the model is actually not a machine learning algorithm and this is just for educational purposes, it will not be an issue. We are just using this approach to learn what the naive model would have predicted even on the data it trained on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d6899b87013cac498015a59523d6f5fc",
     "grade": false,
     "grade_id": "cell-bd4beeead806b52d",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Create three classifers that predict always 0, 1, and 2\n",
    "# Name them always_zero, always_one and always_two respectively\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5f1007b63c813551e9e24d6519493763",
     "grade": true,
     "grade_id": "cell-522eb486ae501239",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert always_zero.approach==\"always\"\n",
    "assert always_zero.value == 0\n",
    "assert always_one.approach==\"always\"\n",
    "assert always_one.value == 1\n",
    "assert always_two.approach==\"always\"\n",
    "assert always_two.value == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "ca9ad85d57aa05f8982f78f82bfbb0d9",
     "grade": false,
     "grade_id": "cell-46ead0e0ddbe2d1e",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Create a classifer that predicts the most frequent class\n",
    "# Name it most_est\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "de2edf8b4addac9a343f0a95ba40c188",
     "grade": true,
     "grade_id": "cell-b8897d0392ce989e",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert most_est.approach==\"most\"\n",
    "most_est.fit([0,0,0,0,0], [0,1,1,1,0])\n",
    "assert most_est.predict([0,0,0]) == [1, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "a89a20e3857151da03a35a707efaa20a",
     "grade": false,
     "grade_id": "cell-6dd3561533dc7fab",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Create a classifer that predicts based on the distribution of the classes\n",
    "# Name it dist_est\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1cb1c2331e7dcbd7abf86935da4cef23",
     "grade": true,
     "grade_id": "cell-333373b5985f80a3",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert dist_est.approach == \"distribution\"\n",
    "dist_est.fit([0,0,0,0,0], [0,0,1,1,1])\n",
    "random.seed(0)\n",
    "assert sum(dist_est.predict([0,0,0,0,0])) == 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "bd5dbac962f0f4ca653eb8e8c80057a9",
     "grade": false,
     "grade_id": "cell-b60f6f134886db8f",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Create a classifer that predicts equally any of the classes\n",
    "# Name it equal_est\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "087b190e1eb7e16e6af8ec00dc2b73a4",
     "grade": true,
     "grade_id": "cell-a6244fa35c54a4b6",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert equal_est.approach == \"equal\"\n",
    "equal_est.fit([0,0,0,0,0], [0,1,1,1,1])\n",
    "random.seed(0)\n",
    "assert sum(equal_est.predict([0,0,0,0])) == 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    {\n",
    "        \"name\": \"Always Zero\",\n",
    "        \"estimator\": always_zero\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Always One\",\n",
    "        \"estimator\": always_one\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Always Two\",\n",
    "        \"estimator\": always_two\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Most Common\",\n",
    "        \"estimator\": most_est\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Distribution Based\",\n",
    "        \"estimator\": dist_est\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Equally\",\n",
    "        \"estimator\": equal_est\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "40fc223fad2f83f71f1e6fb1e9083339",
     "grade": true,
     "grade_id": "cell-4fa0002da84133fb",
     "locked": false,
     "points": 70,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# For each dataset, apply each estimator and save the predictions as pred\n",
    "for dataset in datasets:\n",
    "    name = dataset[\"name\"]\n",
    "    labels = dataset[\"labels\"]\n",
    "    print(\"=\"*20)\n",
    "    print(f\"{name}\")\n",
    "    print(\"=\"*20)\n",
    "    for est in estimators:\n",
    "        estimator_name = est[\"name\"]\n",
    "        print(\"-\"*20)\n",
    "        print(f\"Estimating with {estimator_name}\")\n",
    "        print(\"-\"*20)\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "        print(f\"Produced an accuracy score of {accuracy_score(labels, pred)} and the following report\")\n",
    "        print(classification_report(labels, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "389cdf459cce5380870da35116edc90b",
     "grade": true,
     "grade_id": "cell-9b05ea606e1c0cd8",
     "locked": false,
     "points": 80,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Please describe your conclusions based on the above results\n",
    "# You must write at least 300 characters\n",
    "# This portion is worth 100 points (20% of CS)\n",
    "# Save your answer to conclusions\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "print(conclusions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f96902f6df775132e627f13cb16c2783",
     "grade": true,
     "grade_id": "cell-355d52c0428b75f3",
     "locked": true,
     "points": 20,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(conclusions) > 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "35c02446ada971330235203f8d3b177f",
     "grade": false,
     "grade_id": "cell-d45e75d8071c765c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "cc89e0660ccb53529a249ada6cc1a0cd",
     "grade": false,
     "grade_id": "cell-fb93624c53422815",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def feedback():\n",
    "    \"\"\"Provide feedback on the contents of this exercise\n",
    "    \n",
    "    Returns:\n",
    "        string\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "51c4d2a5734ab18322474a6f62fb5382",
     "grade": true,
     "grade_id": "cell-10ee4b2b9ba4be3d",
     "locked": true,
     "points": 0,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
