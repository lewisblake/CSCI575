{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "37f776e4e1c8c3965f5bc354f8a83aef",
     "grade": false,
     "grade_id": "cell-c3b11c5d81596cb7",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    " As this is a case study individual assignment, I agree and acknowledge that all code modified in this notebook is my own. I have not and will not collaborate with anyone on this assignment. If I have questions, I will ask the instructor or TAs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "029dbc0bc45912b6ed8a9d4e68876a98",
     "grade": false,
     "grade_id": "cell-7a410150ea339a11",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Please provide your name and agreement to the above statement as variables `name` (string) and `agree` (boolean)\n",
    "# YOUR CODE HERE\n",
    "name = \"Lewis Blake\"\n",
    "agree = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "af5055b179decaf7c280171f297f036c",
     "grade": true,
     "grade_id": "cell-be8f2fd5450b57d8",
     "locked": true,
     "points": 0,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "conditions = [isinstance(name, str), isinstance(agree, bool), agree]\n",
    "for condition in conditions:\n",
    "    if not condition:\n",
    "        raise ValueError(\"Student has not agreed to work on this assignment alone and without collaboration or has not provided their name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4d0698f98a2a7060ac16b6b48aeff7fd",
     "grade": false,
     "grade_id": "cell-331eb85546d2d12e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Naive Classification Approaches\n",
    "\n",
    "\n",
    "In this case study, we will build a custom classifier that takes some naive classification approaches. The approaches we'll take are:\n",
    "\n",
    "- Guessing one class at all times\n",
    "- Guessing the most common class at all times\n",
    "- Guessing randomly based on the distribution of the classes\n",
    "- Guessing randomly based on an equal chance of the classes\n",
    "\n",
    "\n",
    "We're going to build a class, `NaiveClassifier`, that can fit and predict based on the above approaches. We will then try it out on a few datasets and see what results we get. This should help you understand the minimal performance you should expect out of your machine learning models.\n",
    "\n",
    "The way `NaiveClassifier` should work is that we instantiate it with an `approach` and an optional `value` depending on the method.\n",
    "\n",
    "Examples:\n",
    "\n",
    "- always predict class 1 would be: `clf = NaiveClassifier(approach=\"always\", value=1)`\n",
    "- always predict most common class would be: `clf = NaiveClassifier(approach=\"most\")`\n",
    "- predict based on class distribution: `clf = NaiveClassifier(approach=\"distribution\")`\n",
    "- predict based on equal class distribution: `clf = NaiveClassifier(approach=\"equal\")`\n",
    "\n",
    "Note that as a naive classifier, this classifier is not using any of the features about the data. It is only using the patterns that it detects in the labels.\n",
    "\n",
    "In addition, recall that the way a supervised learning classifier works is that it is:\n",
    "\n",
    "- Initialized with its hyperparameters\n",
    "- When running `.fit()`, it learns its model parameters such as the weight coefficients in linear regression.\n",
    "- When running `.predict`, it applies the model parameters that it learned to the new data such as plugging in values of $x$ into the equation $y=mx+b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7150a9a2cf9e261ee812b05e651f385f",
     "grade": false,
     "grade_id": "cell-9213e34f09e91de2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import stats\n",
    "import sklearn\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "612b4a613bb8950aaa69fc8bdd1a9974",
     "grade": false,
     "grade_id": "cell-2072e6f2de42e5af",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def select_most_common(labels):\n",
    "    \"\"\"Select the most common value in an iterable of labels\n",
    "    \n",
    "    Args:\n",
    "        labels (iterable): An iterable of integers representing the labels of a dataset\n",
    "    \n",
    "    Returns:\n",
    "        int: The most common element in the iterable\n",
    "    \"\"\"\n",
    "    return max(set(labels), key = labels.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7f10cadf9d39cca14641dae7f0c71454",
     "grade": true,
     "grade_id": "cell-8e5505cea4302a14",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert select_most_common([1,2,2,3,4,5]) == 2\n",
    "assert select_most_common([1,1,1,1,1,1,2,2,2]) == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ff9f379b5c97f08e2e1294c6fc237c83",
     "grade": false,
     "grade_id": "cell-325a895cdb54e984",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "In this next portion, we will generate data following a distribution. Let's go over a simple example of how to do that. If we want to simulate a fair coin flip, we know that 50% of the time we should get heads, and 50% of the time we should get tails. We can create a simulated fair coin programmatically by generating a *uniform* random number between 0 and 1, and deciding that if it is less than 0.5, we get heads, and if it is greater than or equal to 0.5 we get tails. We can programatically represent the distribution of heads and tails as `[0.5, 0.5]` where heads is class 0 and tails is class 1. In the next function, you will write a function to generate data / predict from a distribution where the distribution is represented that way and can be of any length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "62dd94396852ddf43fe6481a9bcc2448",
     "grade": true,
     "grade_id": "cell-4547cb50665c9747",
     "locked": false,
     "points": 20,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def predict_from_distribution(distribution):\n",
    "    \"\"\"Return one possible value given a distribution\n",
    "    \n",
    "    Args:\n",
    "        distribution (list): A list of probabilities of each class index\n",
    "        \n",
    "    Returns:\n",
    "        int: The index of the predicted class.\n",
    "    \"\"\"\n",
    "    x = random.random()\n",
    "    for i in range(len(distribution)):\n",
    "        #x = random.random()\n",
    "        if x < distribution[0]:\n",
    "            return 0\n",
    "        elif x < sum(distribution[0:i+1]):\n",
    "            return i\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8ebc09ff2b2ab3f7a2f880ec0ceebcf1",
     "grade": false,
     "grade_id": "cell-bcf996323af296d9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 1, 0, 2, 0, 1, 2, 0, 2]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example predictions\n",
    "# You should see 10 results with about 5 0s, 1 1, and 4 2's.\n",
    "# You can print val in order to see if it's being calculated correctly\n",
    "[predict_from_distribution([0.5, 0.1, 0.4]) for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d98b468ae54931df1cb7161cde8f1e4a",
     "grade": false,
     "grade_id": "cell-317516af1385c134",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "class NaiveClassifier:\n",
    "    \"\"\"A Naive Classifier that predicts classes using simple approaches.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, approach, value=None):\n",
    "        \"\"\"Initialize the NaiveClassifier\n",
    "        \n",
    "        Args:\n",
    "            approach (str): One of \"always\", \"most\", \"distribution\", \"equal\"\n",
    "            value (int, optional): Defaults to None. The value of the class to select if approach is \"always\"\n",
    "        \"\"\"\n",
    "        assert approach in [\"always\", \"most\", \"distribution\", \"equal\"]\n",
    "        self.approach = approach\n",
    "        self.value = value\n",
    "\n",
    "    def fit(self,X,y):\n",
    "        \"\"\"Fit to data and labels\n",
    "        \n",
    "        Args:\n",
    "            X (iterable): The features of the data\n",
    "            y (iterable): The labels of the data\n",
    "        \"\"\"\n",
    "        if self.approach == \"always\":\n",
    "            # If the user does not supply a inital value, set it to 0\n",
    "            if self.value == None:\n",
    "                self.value = 0\n",
    "        elif self.approach == \"most\":\n",
    "            # use the select_most_common() function previous written and set to most common.\n",
    "            most_common = [select_most_common(y)]\n",
    "            self.most_common = most_common\n",
    "        elif self.approach == \"distribution\":\n",
    "            dist = [y.count(i)/len(y) for i in range(len(set(y)))]\n",
    "            #dist_fit = [predict_from_distribution(dist) for i in range(len(X))]\n",
    "            self.dist = dist\n",
    "        elif self.approach == \"equal\":\n",
    "            #num_classes = len(set(y))\n",
    "            #dist = [1/num_classes]*len(X)\n",
    "            #equal_fit = [predict_from_distribution(dist) for i in range(len(X))]\n",
    "            #self.dist = dist\n",
    "            self.unique_labels = np.unique(y)\n",
    "    def predict(self,X):\n",
    "        \"\"\"Predict the labels of a new set of datapoints\n",
    "        \n",
    "        Args:\n",
    "            X (iterable): The data to predict\n",
    "        \"\"\"\n",
    "        if self.approach == \"always\":\n",
    "            # \"always\" returns self.value\n",
    "            value = self.value\n",
    "            pred = [value]*len(X)\n",
    "            return pred\n",
    "        elif self.approach == \"most\":\n",
    "            most_common = self.most_common\n",
    "            pred = most_common*len(X)\n",
    "            return pred\n",
    "        elif self.approach == \"distribution\":\n",
    "            dist = self.dist\n",
    "            pred = [predict_from_distribution(dist) for i in range(len(X))]\n",
    "            return pred\n",
    "        elif self.approach == \"equal\":\n",
    "            #dist = self.dist\n",
    "            #pred = [predict_from_distribution(dist) for i in range(len(X))]\n",
    "            unique_labels = self.unique_labels\n",
    "            pred = [random.choice(unique_labels) for i in range(len(X))]\n",
    "            return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8c4619d46be0064b24af31c290541474",
     "grade": false,
     "grade_id": "cell-a22c0b698e77fade",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Let's create a few datasets that we'll use to analyze how a predictor would work with each of those approaches. Here are all the datasets we'll create:\n",
    "\n",
    "- 2 classes equally distributed\n",
    "- 2 classes with 0 at 90% and 1 at 10%\n",
    "- 3 classes equally distributed\n",
    "- 3 classes with 0 at 90%, 1 at 9% and 2 at 1%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "815c4a748b18da09e242491d772a3f70",
     "grade": false,
     "grade_id": "cell-41dd1414621c39ae",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will create the labels for each of the listed datasets with length n\n",
    "# Create the listed datasets as binary_equal, binary_unequal, trinary_equal and trinary_unequal\n",
    "n = 15000\n",
    "features = np.zeros((n,3))\n",
    "\n",
    "binary_equal = np.concatenate( ([0]*7500, [1]*7500), axis = None)\n",
    "binary_unequal = np.concatenate( ([0]*13500, [1]*1500), axis = None)\n",
    "trinary_equal = np.concatenate( ([0]*5000, [1]*5000, [2]*5000), axis = None)\n",
    "trinary_unequal = np.concatenate( ([0]*13500, [1]*1350, [2]*150), axis = None)\n",
    "\n",
    "np.random.shuffle(binary_equal)\n",
    "np.random.shuffle(binary_unequal)\n",
    "np.random.shuffle(trinary_equal)\n",
    "np.random.shuffle(trinary_unequal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "95b318c451acafebc1ef5cf792408b8b",
     "grade": true,
     "grade_id": "cell-7458977b6dde20e7",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.all(np.bincount(binary_equal) == np.array([7500,7500]))\n",
    "assert np.all(np.bincount(binary_unequal) == np.array([13500,1500]))\n",
    "assert np.all(np.bincount(trinary_equal) == np.array([5000,5000,5000]))\n",
    "assert np.all(np.bincount(trinary_unequal) == np.array([13500,1350,150]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1695b48d77fcea33800cc7d8d2fe39f0",
     "grade": false,
     "grade_id": "cell-900b0957df9f3734",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "datasets = [{\n",
    "    \"name\": \"Binary Classification Equally Distributed\",\n",
    "    \"labels\": binary_equal\n",
    "},{\n",
    "    \"name\": \"Binary Classification 90:10\",\n",
    "    \"labels\": binary_unequal\n",
    "},{\n",
    "    \"name\": \"3-Class Classification Equally Distributed\",\n",
    "    \"labels\": trinary_equal\n",
    "},{\n",
    "    \"name\": \"3-Class Classification 90:9:1\",\n",
    "    \"labels\": trinary_unequal\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0ae7ec3f0991ed547340d10b66be6e30",
     "grade": false,
     "grade_id": "cell-c91e34d42c72031a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Testing\n",
    "\n",
    "Let's now test out our Naive Classifiers on the above datasets. We will be training and testing on the full dataset. Since the model is actually not a machine learning algorithm and this is just for educational purposes, it will not be an issue. We are just using this approach to learn what the naive model would have predicted even on the data it trained on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d6899b87013cac498015a59523d6f5fc",
     "grade": false,
     "grade_id": "cell-bd4beeead806b52d",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Create three classifers that predict always 0, 1, and 2\n",
    "# Name them always_zero, always_one and always_two respectively\n",
    "\n",
    "always_zero = NaiveClassifier(approach=\"always\", value = 0)\n",
    "always_one = NaiveClassifier(approach=\"always\", value = 1)\n",
    "always_two = NaiveClassifier(approach=\"always\", value = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5f1007b63c813551e9e24d6519493763",
     "grade": true,
     "grade_id": "cell-522eb486ae501239",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert always_zero.approach==\"always\"\n",
    "assert always_zero.value == 0\n",
    "assert always_one.approach==\"always\"\n",
    "assert always_one.value == 1\n",
    "assert always_two.approach==\"always\"\n",
    "assert always_two.value == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "ca9ad85d57aa05f8982f78f82bfbb0d9",
     "grade": false,
     "grade_id": "cell-46ead0e0ddbe2d1e",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Create a classifer that predicts the most frequent class\n",
    "# Name it most_est\n",
    "most_est = NaiveClassifier(approach=\"most\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "de2edf8b4addac9a343f0a95ba40c188",
     "grade": true,
     "grade_id": "cell-b8897d0392ce989e",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert most_est.approach==\"most\"\n",
    "most_est.fit([0,0,0,0,0], [0,1,1,1,0])\n",
    "assert most_est.predict([0,0,0]) == [1, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "a89a20e3857151da03a35a707efaa20a",
     "grade": false,
     "grade_id": "cell-6dd3561533dc7fab",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Create a classifer that predicts based on the distribution of the classes\n",
    "# Name it dist_est\n",
    "dist_est = NaiveClassifier(approach=\"distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1cb1c2331e7dcbd7abf86935da4cef23",
     "grade": true,
     "grade_id": "cell-333373b5985f80a3",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert dist_est.approach == \"distribution\"\n",
    "dist_est.fit([0,0,0,0,0], [0,0,1,1,1])\n",
    "random.seed(0)\n",
    "assert sum(dist_est.predict([0,0,0,0,0])) == 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "bd5dbac962f0f4ca653eb8e8c80057a9",
     "grade": false,
     "grade_id": "cell-b60f6f134886db8f",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Create a classifer that predicts equally any of the classes\n",
    "# Name it equal_est\n",
    "equal_est = NaiveClassifier(approach=\"equal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "087b190e1eb7e16e6af8ec00dc2b73a4",
     "grade": true,
     "grade_id": "cell-a6244fa35c54a4b6",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert equal_est.approach == \"equal\"\n",
    "equal_est.fit([0,0,0,0,0], [0,1,1,1,1])\n",
    "random.seed(0)\n",
    "assert sum(equal_est.predict([0,0,0,0])) == 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    {\n",
    "        \"name\": \"Always Zero\",\n",
    "        \"estimator\": always_zero\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Always One\",\n",
    "        \"estimator\": always_one\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Always Two\",\n",
    "        \"estimator\": always_two\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Most Common\",\n",
    "        \"estimator\": most_est\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Distribution Based\",\n",
    "        \"estimator\": dist_est\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Equally\",\n",
    "        \"estimator\": equal_est\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "40fc223fad2f83f71f1e6fb1e9083339",
     "grade": true,
     "grade_id": "cell-4fa0002da84133fb",
     "locked": false,
     "points": 70,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "Binary Classification Equally Distributed\n",
      "====================\n",
      "--------------------\n",
      "Estimating with Always Zero\n",
      "--------------------\n",
      "Produced an accuracy score of 0.5 and the following report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      1.00      0.67      7500\n",
      "          1       0.00      0.00      0.00      7500\n",
      "\n",
      "avg / total       0.25      0.50      0.33     15000\n",
      "\n",
      "--------------------\n",
      "Estimating with Always One\n",
      "--------------------\n",
      "Produced an accuracy score of 0.5 and the following report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00      7500\n",
      "          1       0.50      1.00      0.67      7500\n",
      "\n",
      "avg / total       0.25      0.50      0.33     15000\n",
      "\n",
      "--------------------\n",
      "Estimating with Always Two\n",
      "--------------------\n",
      "Produced an accuracy score of 0.0 and the following report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00      7500\n",
      "          1       0.00      0.00      0.00      7500\n",
      "          2       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.00      0.00      0.00     15000\n",
      "\n",
      "--------------------\n",
      "Estimating with Most Common\n",
      "--------------------\n",
      "Produced an accuracy score of 0.5 and the following report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      1.00      0.67      7500\n",
      "          1       0.00      0.00      0.00      7500\n",
      "\n",
      "avg / total       0.25      0.50      0.33     15000\n",
      "\n",
      "--------------------\n",
      "Estimating with Distribution Based\n",
      "--------------------\n",
      "Produced an accuracy score of 0.5002666666666666 and the following report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.51      0.50      7500\n",
      "          1       0.50      0.49      0.50      7500\n",
      "\n",
      "avg / total       0.50      0.50      0.50     15000\n",
      "\n",
      "--------------------\n",
      "Estimating with Equally\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Produced an accuracy score of 0.5056 and the following report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.51      0.50      0.50      7500\n",
      "          1       0.51      0.51      0.51      7500\n",
      "\n",
      "avg / total       0.51      0.51      0.51     15000\n",
      "\n",
      "====================\n",
      "Binary Classification 90:10\n",
      "====================\n",
      "--------------------\n",
      "Estimating with Always Zero\n",
      "--------------------\n",
      "Produced an accuracy score of 0.9 and the following report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      1.00      0.95     13500\n",
      "          1       0.00      0.00      0.00      1500\n",
      "\n",
      "avg / total       0.81      0.90      0.85     15000\n",
      "\n",
      "--------------------\n",
      "Estimating with Always One\n",
      "--------------------\n",
      "Produced an accuracy score of 0.1 and the following report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00     13500\n",
      "          1       0.10      1.00      0.18      1500\n",
      "\n",
      "avg / total       0.01      0.10      0.02     15000\n",
      "\n",
      "--------------------\n",
      "Estimating with Always Two\n",
      "--------------------\n",
      "Produced an accuracy score of 0.0 and the following report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00     13500\n",
      "          1       0.00      0.00      0.00      1500\n",
      "          2       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.00      0.00      0.00     15000\n",
      "\n",
      "--------------------\n",
      "Estimating with Most Common\n",
      "--------------------\n",
      "Produced an accuracy score of 0.9 and the following report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      1.00      0.95     13500\n",
      "          1       0.00      0.00      0.00      1500\n",
      "\n",
      "avg / total       0.81      0.90      0.85     15000\n",
      "\n",
      "--------------------\n",
      "Estimating with Distribution Based\n",
      "--------------------\n",
      "Produced an accuracy score of 0.8222666666666667 and the following report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.90      0.90     13500\n",
      "          1       0.11      0.11      0.11      1500\n",
      "\n",
      "avg / total       0.82      0.82      0.82     15000\n",
      "\n",
      "--------------------\n",
      "Estimating with Equally\n",
      "--------------------\n",
      "Produced an accuracy score of 0.4968 and the following report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.50      0.64     13500\n",
      "          1       0.10      0.49      0.16      1500\n",
      "\n",
      "avg / total       0.82      0.50      0.59     15000\n",
      "\n",
      "====================\n",
      "3-Class Classification Equally Distributed\n",
      "====================\n",
      "--------------------\n",
      "Estimating with Always Zero\n",
      "--------------------\n",
      "Produced an accuracy score of 0.3333333333333333 and the following report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.33      1.00      0.50      5000\n",
      "          1       0.00      0.00      0.00      5000\n",
      "          2       0.00      0.00      0.00      5000\n",
      "\n",
      "avg / total       0.11      0.33      0.17     15000\n",
      "\n",
      "--------------------\n",
      "Estimating with Always One\n",
      "--------------------\n",
      "Produced an accuracy score of 0.3333333333333333 and the following report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00      5000\n",
      "          1       0.33      1.00      0.50      5000\n",
      "          2       0.00      0.00      0.00      5000\n",
      "\n",
      "avg / total       0.11      0.33      0.17     15000\n",
      "\n",
      "--------------------\n",
      "Estimating with Always Two\n",
      "--------------------\n",
      "Produced an accuracy score of 0.3333333333333333 and the following report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00      5000\n",
      "          1       0.00      0.00      0.00      5000\n",
      "          2       0.33      1.00      0.50      5000\n",
      "\n",
      "avg / total       0.11      0.33      0.17     15000\n",
      "\n",
      "--------------------\n",
      "Estimating with Most Common\n",
      "--------------------\n",
      "Produced an accuracy score of 0.3333333333333333 and the following report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.33      1.00      0.50      5000\n",
      "          1       0.00      0.00      0.00      5000\n",
      "          2       0.00      0.00      0.00      5000\n",
      "\n",
      "avg / total       0.11      0.33      0.17     15000\n",
      "\n",
      "--------------------\n",
      "Estimating with Distribution Based\n",
      "--------------------\n",
      "Produced an accuracy score of 0.32886666666666664 and the following report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.33      0.32      0.33      5000\n",
      "          1       0.33      0.33      0.33      5000\n",
      "          2       0.33      0.33      0.33      5000\n",
      "\n",
      "avg / total       0.33      0.33      0.33     15000\n",
      "\n",
      "--------------------\n",
      "Estimating with Equally\n",
      "--------------------\n",
      "Produced an accuracy score of 0.33513333333333334 and the following report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.33      0.33      0.33      5000\n",
      "          1       0.34      0.34      0.34      5000\n",
      "          2       0.34      0.33      0.33      5000\n",
      "\n",
      "avg / total       0.34      0.34      0.34     15000\n",
      "\n",
      "====================\n",
      "3-Class Classification 90:9:1\n",
      "====================\n",
      "--------------------\n",
      "Estimating with Always Zero\n",
      "--------------------\n",
      "Produced an accuracy score of 0.9 and the following report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      1.00      0.95     13500\n",
      "          1       0.00      0.00      0.00      1350\n",
      "          2       0.00      0.00      0.00       150\n",
      "\n",
      "avg / total       0.81      0.90      0.85     15000\n",
      "\n",
      "--------------------\n",
      "Estimating with Always One\n",
      "--------------------\n",
      "Produced an accuracy score of 0.09 and the following report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00     13500\n",
      "          1       0.09      1.00      0.17      1350\n",
      "          2       0.00      0.00      0.00       150\n",
      "\n",
      "avg / total       0.01      0.09      0.01     15000\n",
      "\n",
      "--------------------\n",
      "Estimating with Always Two\n",
      "--------------------\n",
      "Produced an accuracy score of 0.01 and the following report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00     13500\n",
      "          1       0.00      0.00      0.00      1350\n",
      "          2       0.01      1.00      0.02       150\n",
      "\n",
      "avg / total       0.00      0.01      0.00     15000\n",
      "\n",
      "--------------------\n",
      "Estimating with Most Common\n",
      "--------------------\n",
      "Produced an accuracy score of 0.9 and the following report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      1.00      0.95     13500\n",
      "          1       0.00      0.00      0.00      1350\n",
      "          2       0.00      0.00      0.00       150\n",
      "\n",
      "avg / total       0.81      0.90      0.85     15000\n",
      "\n",
      "--------------------\n",
      "Estimating with Distribution Based\n",
      "--------------------\n",
      "Produced an accuracy score of 0.8184 and the following report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.90      0.90     13500\n",
      "          1       0.09      0.09      0.09      1350\n",
      "          2       0.01      0.01      0.01       150\n",
      "\n",
      "avg / total       0.82      0.82      0.82     15000\n",
      "\n",
      "--------------------\n",
      "Estimating with Equally\n",
      "--------------------\n",
      "Produced an accuracy score of 0.33513333333333334 and the following report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.34      0.49     13500\n",
      "          1       0.09      0.32      0.14      1350\n",
      "          2       0.01      0.34      0.02       150\n",
      "\n",
      "avg / total       0.82      0.34      0.45     15000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For each dataset, apply each estimator and save the predictions as pred\n",
    "for dataset in datasets:\n",
    "    name = dataset[\"name\"]\n",
    "    labels = dataset[\"labels\"]\n",
    "    print(\"=\"*20)\n",
    "    print(f\"{name}\")\n",
    "    print(\"=\"*20)\n",
    "    for est in estimators:\n",
    "        estimator_name = est[\"name\"]\n",
    "        print(\"-\"*20)\n",
    "        print(f\"Estimating with {estimator_name}\")\n",
    "        print(\"-\"*20)\n",
    "        # YOUR CODE HERE\n",
    "        estimator = est[\"estimator\"]\n",
    "        estimator.fit(list(features), list(labels) )\n",
    "        pred = estimator.predict(labels)\n",
    "        print(f\"Produced an accuracy score of {accuracy_score(labels, pred)} and the following report\")\n",
    "        print(classification_report(labels, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "389cdf459cce5380870da35116edc90b",
     "grade": true,
     "grade_id": "cell-9b05ea606e1c0cd8",
     "locked": false,
     "points": 80,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Just because a given metric is high on a test data set does not mean that the model is actually a good representation of the data. Testing a the model on a test data set is very important. If, for example, the F1-score is very different between the training and the test data, this is an indication that the model is suboptimal. Moreover, it is important to understand the spread of the data (i.e., how many labels we have for each class) to assess model validity.\n"
     ]
    }
   ],
   "source": [
    "# Please describe your conclusions based on the above results\n",
    "# You must write at least 300 characters\n",
    "# This portion is worth 100 points (20% of CS)\n",
    "# Save your answer to conclusions\n",
    "# YOUR CODE HERE\n",
    "conclusions = \"Just because a given metric is high on a test data set does not mean that the model is actually a good representation of the data. Testing a the model on a test data set is very important. If, for example, the F1-score is very different between the training and the test data, this is an indication that the model is suboptimal. Moreover, it is important to understand the spread of the data (i.e., how many labels we have for each class) to assess model validity.\"\n",
    "print(conclusions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f96902f6df775132e627f13cb16c2783",
     "grade": true,
     "grade_id": "cell-355d52c0428b75f3",
     "locked": true,
     "points": 20,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(conclusions) > 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "35c02446ada971330235203f8d3b177f",
     "grade": false,
     "grade_id": "cell-d45e75d8071c765c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "cc89e0660ccb53529a249ada6cc1a0cd",
     "grade": false,
     "grade_id": "cell-fb93624c53422815",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def feedback():\n",
    "    \"\"\"Provide feedback on the contents of this exercise\n",
    "    \n",
    "    Returns:\n",
    "        string\n",
    "    \"\"\"\n",
    "    return \"This Case Study could have been a lot easier if there was more initial direction about the expectations. For instance, necessitating that we use one package over the other or create our own functions for built-in ones was not initally clearly specified and resulted in a lot of time being wasted. The overall goal of this Case Study however is important and this was a good exercise in measuring baseline performance of machine learning models.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "51c4d2a5734ab18322474a6f62fb5382",
     "grade": true,
     "grade_id": "cell-10ee4b2b9ba4be3d",
     "locked": true,
     "points": 0,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
